{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import skforecast\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.utils import save_forecaster\n",
    "from skforecast.utils import load_forecaster\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo Dataset principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/Top100_prediction_con.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>store</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>item</th>\n",
       "      <th>store_code</th>\n",
       "      <th>yearweek</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>weekday</th>\n",
       "      <th>event</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>ACCESORIES_1_108_NYC_1</td>\n",
       "      <td>Greenwich_Village</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>4</td>\n",
       "      <td>ACCESORIES_1_108</td>\n",
       "      <td>NYC_1</td>\n",
       "      <td>201105</td>\n",
       "      <td>16.1196</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.4784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>591</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_027_NYC_1</td>\n",
       "      <td>Greenwich_Village</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>4</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_027</td>\n",
       "      <td>NYC_1</td>\n",
       "      <td>201105</td>\n",
       "      <td>6.5500</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>615</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_053_NYC_1</td>\n",
       "      <td>Greenwich_Village</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_053</td>\n",
       "      <td>NYC_1</td>\n",
       "      <td>201105</td>\n",
       "      <td>18.7125</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_140_NYC_1</td>\n",
       "      <td>Greenwich_Village</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>4</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_140</td>\n",
       "      <td>NYC_1</td>\n",
       "      <td>201105</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>737</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_177_NYC_1</td>\n",
       "      <td>Greenwich_Village</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_177</td>\n",
       "      <td>NYC_1</td>\n",
       "      <td>201105</td>\n",
       "      <td>9.9625</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         id              store        date  \\\n",
       "0         103     ACCESORIES_1_108_NYC_1  Greenwich_Village  2011-01-29   \n",
       "1         591  HOME_&_GARDEN_1_027_NYC_1  Greenwich_Village  2011-01-29   \n",
       "2         615  HOME_&_GARDEN_1_053_NYC_1  Greenwich_Village  2011-01-29   \n",
       "3         700  HOME_&_GARDEN_1_140_NYC_1  Greenwich_Village  2011-01-29   \n",
       "4         737  HOME_&_GARDEN_1_177_NYC_1  Greenwich_Village  2011-01-29   \n",
       "\n",
       "   sales                 item store_code  yearweek  sell_price   weekday  \\\n",
       "0      4     ACCESORIES_1_108      NYC_1    201105     16.1196  Saturday   \n",
       "1      4  HOME_&_GARDEN_1_027      NYC_1    201105      6.5500  Saturday   \n",
       "2      0  HOME_&_GARDEN_1_053      NYC_1    201105     18.7125  Saturday   \n",
       "3      4  HOME_&_GARDEN_1_140      NYC_1    201105     18.7500  Saturday   \n",
       "4      0  HOME_&_GARDEN_1_177      NYC_1    201105      9.9625  Saturday   \n",
       "\n",
       "   event   income  \n",
       "0    0.0  64.4784  \n",
       "1    0.0  26.2000  \n",
       "2    0.0   0.0000  \n",
       "3    0.0  75.0000  \n",
       "4    0.0   0.0000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()\n",
    "df_filtrado = df_original[(df_original['store_code'] == 'BOS_1') & (df_original['item'] == 'SUPERMARKET_3_090')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_predict = df_filtrado[['date', 'income', 'weekday', 'event']]\n",
    "ts_predict = pd.get_dummies(data=ts_predict, columns=['weekday'], dtype=int)\n",
    "ts_predict['date'] = pd.to_datetime(ts_predict['date'])\n",
    "ts_predict.sort_values('date', ascending=True, inplace=True)\n",
    "ts_predict.set_index('date', inplace=True)\n",
    "ts_predict = ts_predict.asfreq('D')\n",
    "y, exog = ts_predict['income'], ts_predict.drop(columns=['income'])\n",
    "y_train, y_test = y[:-30], y[-30:]\n",
    "exog_train, exog_test = exog[:-30], exog[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train)\n",
    "\n",
    "predicciones = forecaster.predict(steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 680.5640958028803\n",
      "El error RMSPE es: 24.88%\n"
     ]
    }
   ],
   "source": [
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100\n",
    "\n",
    "print(f'El error RMSPE es: {rmspe:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>64.13</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>63.59</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>44.11</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>43.92</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>42.05</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>50.84</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>58.03</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>60.29</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>56.46</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>48.33</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>41.72</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>45.57</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>52.17</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>61.48</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>60.45</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>54.06</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>46.14</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>43.04</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>44.84</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>51.42</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>58.01</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>57.95</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>48.27</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>44.39</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>44.41</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>44.04</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>51.12</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>61.80</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>57.41</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>49.73</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pred  test\n",
       "2016-03-26  64.13    67\n",
       "2016-03-27  63.59   113\n",
       "2016-03-28  44.11    36\n",
       "2016-03-29  43.92    35\n",
       "2016-03-30  42.05    43\n",
       "2016-03-31  50.84    57\n",
       "2016-04-01  58.03    44\n",
       "2016-04-02  60.29    81\n",
       "2016-04-03  56.46    67\n",
       "2016-04-04  48.33    56\n",
       "2016-04-05  41.72    50\n",
       "2016-04-06  45.57    43\n",
       "2016-04-07  52.17    42\n",
       "2016-04-08  61.48    59\n",
       "2016-04-09  60.45    64\n",
       "2016-04-10  54.06    79\n",
       "2016-04-11  46.14    55\n",
       "2016-04-12  43.04    35\n",
       "2016-04-13  44.84    35\n",
       "2016-04-14  51.42    36\n",
       "2016-04-15  58.01    60\n",
       "2016-04-16  57.95    68\n",
       "2016-04-17  48.27    69\n",
       "2016-04-18  44.39    48\n",
       "2016-04-19  44.41    34\n",
       "2016-04-20  44.04    49\n",
       "2016-04-21  51.12    39\n",
       "2016-04-22  61.80    59\n",
       "2016-04-23  57.41    45\n",
       "2016-04-24  49.73    58"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CON HIPERPARAMETROS SIN EXOGENAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid: 100%|██████████| 7/7 [07:46<00:00, 66.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4] \n",
      "  Parameters: {'max_depth': 3, 'n_estimators': 250}\n",
      "  Backtesting metric: 3220.2706945470536\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters: grid search\n",
    "# ==============================================================================\n",
    "steps = 14\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 7 # This value will be replaced in the grid search\n",
    "             )\n",
    "\n",
    "# Candidate values for lags\n",
    "lags_grid = [3,4,5,7,8,10,14]\n",
    "\n",
    "# Candidate values for regressor's hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 250],\n",
    "    'max_depth': [3, 8]\n",
    "}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                   forecaster         = forecaster,\n",
    "                   y                  = y_train,\n",
    "                   param_grid         = param_grid,\n",
    "                   lags_grid          = lags_grid,\n",
    "                   steps              = steps,\n",
    "                   metric             = 'mean_squared_error',\n",
    "                   initial_train_size = int(len(y_train)*0.5),\n",
    "                   fixed_train_size   = False,\n",
    "                   refit              = False,\n",
    "                   skip_folds         = None,\n",
    "                   return_best        = True,\n",
    "                   n_jobs             = 'auto',\n",
    "                   verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 919.3605220434499\n",
      "El error RMSPE es: 27.72%\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=10,\n",
    "                                        max_depth=3,\n",
    "                                        #min_samples_leaf=2, \n",
    "                                        #min_samples_split=5,\n",
    "                                        n_estimators=250),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train)\n",
    "\n",
    "predicciones = forecaster.predict(steps=30)\n",
    "\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100\n",
    "\n",
    "print(f'El error RMSPE es: {rmspe:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>93.473865</td>\n",
       "      <td>120.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>100.843957</td>\n",
       "      <td>203.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>91.234561</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>89.670641</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>89.574213</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>89.775443</td>\n",
       "      <td>102.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>110.648462</td>\n",
       "      <td>79.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>90.145226</td>\n",
       "      <td>145.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>95.261071</td>\n",
       "      <td>120.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>90.062785</td>\n",
       "      <td>100.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>89.670641</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>90.238672</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>103.777849</td>\n",
       "      <td>106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>90.062785</td>\n",
       "      <td>115.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>90.417414</td>\n",
       "      <td>142.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>89.863666</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>99.965618</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>90.062785</td>\n",
       "      <td>122.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>89.859879</td>\n",
       "      <td>124.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>86.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>88.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>70.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>94.666099</td>\n",
       "      <td>106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>90.062785</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>89.758863</td>\n",
       "      <td>104.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pred   test\n",
       "2016-03-26   93.473865  120.6\n",
       "2016-03-27  100.843957  203.4\n",
       "2016-03-28   91.234561   64.8\n",
       "2016-03-29   89.670641   63.0\n",
       "2016-03-30   89.574213   77.4\n",
       "2016-03-31   89.775443  102.6\n",
       "2016-04-01  110.648462   79.2\n",
       "2016-04-02   90.145226  145.8\n",
       "2016-04-03   95.261071  120.6\n",
       "2016-04-04   90.062785  100.8\n",
       "2016-04-05   89.758863   90.0\n",
       "2016-04-06   89.670641   77.4\n",
       "2016-04-07   90.238672   75.6\n",
       "2016-04-08  103.777849  106.2\n",
       "2016-04-09   90.062785  115.2\n",
       "2016-04-10   90.417414  142.2\n",
       "2016-04-11   89.758863   99.0\n",
       "2016-04-12   89.758863   63.0\n",
       "2016-04-13   89.758863   63.0\n",
       "2016-04-14   89.863666   64.8\n",
       "2016-04-15   99.965618  108.0\n",
       "2016-04-16   90.062785  122.4\n",
       "2016-04-17   89.859879  124.2\n",
       "2016-04-18   89.758863   86.4\n",
       "2016-04-19   89.758863   61.2\n",
       "2016-04-20   89.758863   88.2\n",
       "2016-04-21   89.758863   70.2\n",
       "2016-04-22   94.666099  106.2\n",
       "2016-04-23   90.062785   81.0\n",
       "2016-04-24   89.758863  104.4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 443.85447463392\n",
      "El error RMSPE es: 18.25%\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=11),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train, exog=exog_train)\n",
    "\n",
    "predicciones = forecaster.predict(steps=30, exog=exog_test)\n",
    "\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100\n",
    "\n",
    "print(f'El error RMSPE es: {rmspe:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>120.39996</td>\n",
       "      <td>120.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>123.20124</td>\n",
       "      <td>203.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>80.80992</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>71.34732</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>78.72912</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>88.91664</td>\n",
       "      <td>102.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>98.72148</td>\n",
       "      <td>79.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>118.19136</td>\n",
       "      <td>145.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>114.30132</td>\n",
       "      <td>120.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>81.51888</td>\n",
       "      <td>100.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>72.82656</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>82.59408</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>80.20656</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>96.25788</td>\n",
       "      <td>106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>119.97240</td>\n",
       "      <td>115.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>111.81420</td>\n",
       "      <td>142.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>77.23776</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>75.92664</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>72.92160</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>78.87000</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>93.44520</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>121.48968</td>\n",
       "      <td>122.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>115.93428</td>\n",
       "      <td>124.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>80.03544</td>\n",
       "      <td>86.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>72.39192</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>71.37144</td>\n",
       "      <td>88.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>75.58896</td>\n",
       "      <td>70.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>92.68752</td>\n",
       "      <td>106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>118.61916</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>115.89204</td>\n",
       "      <td>104.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred   test\n",
       "2016-03-26  120.39996  120.6\n",
       "2016-03-27  123.20124  203.4\n",
       "2016-03-28   80.80992   64.8\n",
       "2016-03-29   71.34732   63.0\n",
       "2016-03-30   78.72912   77.4\n",
       "2016-03-31   88.91664  102.6\n",
       "2016-04-01   98.72148   79.2\n",
       "2016-04-02  118.19136  145.8\n",
       "2016-04-03  114.30132  120.6\n",
       "2016-04-04   81.51888  100.8\n",
       "2016-04-05   72.82656   90.0\n",
       "2016-04-06   82.59408   77.4\n",
       "2016-04-07   80.20656   75.6\n",
       "2016-04-08   96.25788  106.2\n",
       "2016-04-09  119.97240  115.2\n",
       "2016-04-10  111.81420  142.2\n",
       "2016-04-11   77.23776   99.0\n",
       "2016-04-12   75.92664   63.0\n",
       "2016-04-13   72.92160   63.0\n",
       "2016-04-14   78.87000   64.8\n",
       "2016-04-15   93.44520  108.0\n",
       "2016-04-16  121.48968  122.4\n",
       "2016-04-17  115.93428  124.2\n",
       "2016-04-18   80.03544   86.4\n",
       "2016-04-19   72.39192   61.2\n",
       "2016-04-20   71.37144   88.2\n",
       "2016-04-21   75.58896   70.2\n",
       "2016-04-22   92.68752  106.2\n",
       "2016-04-23  118.61916   81.0\n",
       "2016-04-24  115.89204  104.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 144.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  25%|██▌       | 1/4 [04:01<12:03, 241.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  50%|█████     | 2/4 [08:57<09:07, 273.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  75%|███████▌  | 3/4 [13:47<04:40, 280.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid: 100%|██████████| 4/4 [20:13<00:00, 303.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6 7] \n",
      "  Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "  Backtesting metric: 658.0679637318843\n",
      "\n",
      "Mejores parámetros:                                                lags  \\\n",
      "33                            [1, 2, 3, 4, 5, 6, 7]   \n",
      "69  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "61  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "66  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "63  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "..                                              ...   \n",
      "4                             [1, 2, 3, 4, 5, 6, 7]   \n",
      "7                             [1, 2, 3, 4, 5, 6, 7]   \n",
      "10                            [1, 2, 3, 4, 5, 6, 7]   \n",
      "36  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "1                             [1, 2, 3, 4, 5, 6, 7]   \n",
      "\n",
      "                                         lags_label  \\\n",
      "33                            [1, 2, 3, 4, 5, 6, 7]   \n",
      "69  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "61  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "66  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "63  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "..                                              ...   \n",
      "4                             [1, 2, 3, 4, 5, 6, 7]   \n",
      "7                             [1, 2, 3, 4, 5, 6, 7]   \n",
      "10                            [1, 2, 3, 4, 5, 6, 7]   \n",
      "36  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "1                             [1, 2, 3, 4, 5, 6, 7]   \n",
      "\n",
      "                                               params  mean_squared_error  \\\n",
      "33  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...          658.067964   \n",
      "69  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...          662.889964   \n",
      "61  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...          664.462278   \n",
      "66  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...          668.384905   \n",
      "63  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...          676.680678   \n",
      "..                                                ...                 ...   \n",
      "4   {'max_depth': None, 'min_samples_leaf': 1, 'mi...          889.292585   \n",
      "7   {'max_depth': None, 'min_samples_leaf': 2, 'mi...          927.487676   \n",
      "10  {'max_depth': None, 'min_samples_leaf': 2, 'mi...          930.656556   \n",
      "36  {'max_depth': None, 'min_samples_leaf': 1, 'mi...          933.590550   \n",
      "1   {'max_depth': None, 'min_samples_leaf': 1, 'mi...          955.649703   \n",
      "\n",
      "    max_depth  min_samples_leaf  min_samples_split  n_estimators  \n",
      "33       10.0               2.0                5.0          50.0  \n",
      "69       10.0               2.0                5.0          50.0  \n",
      "61       10.0               1.0                2.0         100.0  \n",
      "66       10.0               2.0                2.0          50.0  \n",
      "63       10.0               1.0                5.0          50.0  \n",
      "..        ...               ...                ...           ...  \n",
      "4         NaN               1.0                5.0         100.0  \n",
      "7         NaN               2.0                2.0         100.0  \n",
      "10        NaN               2.0                5.0         100.0  \n",
      "36        NaN               1.0                2.0          50.0  \n",
      "1         NaN               1.0                2.0         100.0  \n",
      "\n",
      "[144 rows x 8 columns]\n",
      "Mejor RMSE: 658.0679637318843\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo con un regressor base\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=RandomForestRegressor(random_state=42),\n",
    "    lags=7  # Esta es solo una configuración inicial, la ajustaremos con GridSearch\n",
    ")\n",
    "\n",
    "# Parámetros del RandomForest y los lags a buscar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Número de árboles en el bosque\n",
    "    'max_depth': [None, 5, 10],  # Profundidad máxima de los árboles\n",
    "    'min_samples_split': [2, 5],  # Muestras mínimas para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2],  # Muestras mínimas en una hoja\n",
    "}\n",
    "\n",
    "lags_grid = [7, 14, 21, 30]\n",
    "\n",
    "# Realizar el GridSearch\n",
    "results_grid = grid_search_forecaster(\n",
    "    forecaster=forecaster,\n",
    "    y=y_train,  # Serie temporal de entrenamiento\n",
    "    exog=exog_train,  # Variables exógenas si tienes alguna\n",
    "    param_grid=param_grid,  # La cuadrícula de parámetros\n",
    "    lags_grid=lags_grid,\n",
    "    steps=7,  # Cuántos pasos (días) predecir hacia adelante\n",
    "    metric='mean_squared_error',  # Métrica de evaluación (también puede ser MAE, etc.)\n",
    "    initial_train_size=len(y_train) - 30,  # Tamaño inicial de la ventana de entrenamiento\n",
    "    refit=True,  # Reentrenar el modelo en cada combinación de hiperparámetros\n",
    "    return_best=True,  # Devolver el mejor modelo\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Mostrar los mejores parámetros y el error\n",
    "print(f\"Mejores parámetros: {results_grid}\")\n",
    "print(f\"Mejor RMSE: {results_grid['mean_squared_error'].min()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 374.1265816986876\n",
      "El error RMSPE es: 18.96%\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=10,\n",
    "                                        max_depth=10,\n",
    "                                        min_samples_leaf=2, \n",
    "                                        min_samples_split=5,\n",
    "                                        n_estimators=50),\n",
    "        lags=7\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train, exog=exog_train)\n",
    "\n",
    "predicciones = forecaster.predict(steps=30,exog=exog_test)\n",
    "\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100\n",
    "\n",
    "print(f'El error RMSPE es: {rmspe:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>61.084405</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>70.267286</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>41.432048</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>43.800524</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>42.226000</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>51.304048</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>58.153667</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>71.072429</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>62.956952</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>48.674333</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>44.866238</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>42.861333</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>47.757127</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>61.184576</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>64.349667</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>64.364286</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>47.130000</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>43.337000</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>43.117333</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>51.218238</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>58.770381</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>72.009333</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>65.443429</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>47.791952</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>44.672238</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>42.354556</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>46.227238</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>54.526576</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>62.450952</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>63.039619</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred  test\n",
       "2016-03-26  61.084405    67\n",
       "2016-03-27  70.267286   113\n",
       "2016-03-28  41.432048    36\n",
       "2016-03-29  43.800524    35\n",
       "2016-03-30  42.226000    43\n",
       "2016-03-31  51.304048    57\n",
       "2016-04-01  58.153667    44\n",
       "2016-04-02  71.072429    81\n",
       "2016-04-03  62.956952    67\n",
       "2016-04-04  48.674333    56\n",
       "2016-04-05  44.866238    50\n",
       "2016-04-06  42.861333    43\n",
       "2016-04-07  47.757127    42\n",
       "2016-04-08  61.184576    59\n",
       "2016-04-09  64.349667    64\n",
       "2016-04-10  64.364286    79\n",
       "2016-04-11  47.130000    55\n",
       "2016-04-12  43.337000    35\n",
       "2016-04-13  43.117333    35\n",
       "2016-04-14  51.218238    36\n",
       "2016-04-15  58.770381    60\n",
       "2016-04-16  72.009333    68\n",
       "2016-04-17  65.443429    69\n",
       "2016-04-18  47.791952    48\n",
       "2016-04-19  44.672238    34\n",
       "2016-04-20  42.354556    49\n",
       "2016-04-21  46.227238    39\n",
       "2016-04-22  54.526576    59\n",
       "2016-04-23  62.450952    45\n",
       "2016-04-24  63.039619    58"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "y_train[-30:].plot(ax=ax, label='Train')\n",
    "y_test[-30:].plot(ax=ax, label='Test')\n",
    "predicciones.plot(ax=ax, label='Predictions')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
