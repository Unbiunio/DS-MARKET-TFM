{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skforecast'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mForecasterAutoreg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForecasterAutoreg\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mForecasterAutoregCustom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForecasterAutoregCustom\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skforecast'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import skforecast\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.utils import save_forecaster\n",
    "from skforecast.utils import load_forecaster\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo Dataset principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Top100_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()\n",
    "df_filtrado = df_original[(df_original['store_code'] == 'BOS_1') & (df_original['item'] == 'HOME_&_GARDEN_1_366')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_predict = df_filtrado[['date', 'sales', 'weekday', 'event']]\n",
    "ts_predict = pd.get_dummies(data=ts_predict, columns=['weekday'], dtype=int)\n",
    "ts_predict['date'] = pd.to_datetime(ts_predict['date'])\n",
    "ts_predict.sort_values('date', ascending=True, inplace=True)\n",
    "ts_predict.set_index('date', inplace=True)\n",
    "ts_predict = ts_predict.asfreq('D')\n",
    "y, exog = ts_predict['sales'], ts_predict.drop(columns=['sales'])\n",
    "\n",
    "y_train, y_test = y[:-30], y[-30:]\n",
    "exog_train, exog_test = exog[:-30], exog[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 0.00046493902891965084\n",
      "El error RMSPE es: inf%\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train)\n",
    "predicciones = forecaster.predict(steps=30)\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100\n",
    "\n",
    "print(f'El error RMSPE es: {rmspe:.2f}%')\n",
    "\n",
    "predicciones = forecaster.predict(steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>62.03</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>57.01</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>46.15</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>44.71</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>42.34</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>52.50</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>56.89</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>57.29</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>51.73</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>47.40</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>43.28</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>45.11</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>54.05</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>61.86</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>59.44</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>50.42</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>46.28</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>44.19</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>42.90</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>49.75</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>58.09</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>56.85</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>50.51</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>46.06</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>43.71</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>43.96</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>53.86</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>59.96</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>55.01</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>47.91</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pred  test\n",
       "2016-03-26  62.03    67\n",
       "2016-03-27  57.01   113\n",
       "2016-03-28  46.15    36\n",
       "2016-03-29  44.71    35\n",
       "2016-03-30  42.34    43\n",
       "2016-03-31  52.50    57\n",
       "2016-04-01  56.89    44\n",
       "2016-04-02  57.29    81\n",
       "2016-04-03  51.73    67\n",
       "2016-04-04  47.40    56\n",
       "2016-04-05  43.28    50\n",
       "2016-04-06  45.11    43\n",
       "2016-04-07  54.05    42\n",
       "2016-04-08  61.86    59\n",
       "2016-04-09  59.44    64\n",
       "2016-04-10  50.42    79\n",
       "2016-04-11  46.28    55\n",
       "2016-04-12  44.19    35\n",
       "2016-04-13  42.90    35\n",
       "2016-04-14  49.75    36\n",
       "2016-04-15  58.09    60\n",
       "2016-04-16  56.85    68\n",
       "2016-04-17  50.51    69\n",
       "2016-04-18  46.06    48\n",
       "2016-04-19  43.71    34\n",
       "2016-04-20  43.96    49\n",
       "2016-04-21  53.86    39\n",
       "2016-04-22  59.96    59\n",
       "2016-04-23  55.01    45\n",
       "2016-04-24  47.91    58"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CON HIPERPARAMETROS SIN EXOGENAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid: 100%|██████████| 7/7 [11:31<00:00, 98.73s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
      "  Parameters: {'max_depth': 3, 'n_estimators': 100}\n",
      "  Backtesting metric: 1148.6678367369022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters: grid search\n",
    "# ==============================================================================\n",
    "steps = 7\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 7 # This value will be replaced in the grid search\n",
    "             )\n",
    "\n",
    "# Candidate values for lags\n",
    "lags_grid = [3,4,5,7,8,10,14]\n",
    "\n",
    "# Candidate values for regressor's hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 250],\n",
    "    'max_depth': [3, 8]\n",
    "}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                   forecaster         = forecaster,\n",
    "                   y                  = y_train,\n",
    "                   param_grid         = param_grid,\n",
    "                   lags_grid          = lags_grid,\n",
    "                   steps              = steps,\n",
    "                   metric             = 'mean_squared_error',\n",
    "                   initial_train_size = int(len(y_train)*0.5),\n",
    "                   fixed_train_size   = False,\n",
    "                   refit              = False,\n",
    "                   skip_folds         = None,\n",
    "                   return_best        = True,\n",
    "                   n_jobs             = 'auto',\n",
    "                   verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 294.19223687928906\n",
      "El error RMSPE es: 32.42%\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=10,\n",
    "                                        max_depth=3,\n",
    "                                        #min_samples_leaf=2, \n",
    "                                        #min_samples_split=5,\n",
    "                                        n_estimators=100),\n",
    "        lags=14\n",
    "    )\n",
    "forecaster.fit(y=y_train)\n",
    "predicciones = forecaster.predict(steps=30)\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100\n",
    "\n",
    "print(f'El error RMSPE es: {rmspe:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>57.379534</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>55.198057</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>54.814158</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>60.753981</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>54.817787</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>55.606395</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>54.960332</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>54.586958</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred  test\n",
       "2016-03-26  57.379534    67\n",
       "2016-03-27  55.198057   113\n",
       "2016-03-28  54.814158    36\n",
       "2016-03-29  54.586958    35\n",
       "2016-03-30  54.586958    43\n",
       "2016-03-31  54.586958    57\n",
       "2016-04-01  60.753981    44\n",
       "2016-04-02  54.817787    81\n",
       "2016-04-03  54.586958    67\n",
       "2016-04-04  54.586958    56\n",
       "2016-04-05  54.586958    50\n",
       "2016-04-06  54.586958    43\n",
       "2016-04-07  54.586958    42\n",
       "2016-04-08  55.606395    59\n",
       "2016-04-09  54.586958    64\n",
       "2016-04-10  54.586958    79\n",
       "2016-04-11  54.586958    55\n",
       "2016-04-12  54.586958    35\n",
       "2016-04-13  54.586958    35\n",
       "2016-04-14  54.586958    36\n",
       "2016-04-15  54.960332    60\n",
       "2016-04-16  54.586958    68\n",
       "2016-04-17  54.586958    69\n",
       "2016-04-18  54.586958    48\n",
       "2016-04-19  54.586958    34\n",
       "2016-04-20  54.586958    49\n",
       "2016-04-21  54.586958    39\n",
       "2016-04-22  54.586958    59\n",
       "2016-04-23  54.586958    45\n",
       "2016-04-24  54.586958    58"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 143.49459666666664\n",
      "El error RMSPE es: 19.44%\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=11),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train, exog=exog_train)\n",
    "\n",
    "predicciones = forecaster.predict(steps=30, exog=exog_test)\n",
    "\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100\n",
    "\n",
    "print(f'El error RMSPE es: {rmspe:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>66.07</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>66.83</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>45.36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>45.63</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>42.64</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>50.38</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>50.06</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>61.66</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>61.88</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>48.37</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>42.68</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>44.11</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>45.67</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>58.37</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>65.02</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>61.37</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>46.04</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>44.61</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>41.24</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>47.99</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>57.30</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>67.03</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>64.04</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>45.01</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>42.69</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>41.65</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>48.28</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>59.68</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>65.39</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>62.80</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pred  test\n",
       "2016-03-26  66.07    67\n",
       "2016-03-27  66.83   113\n",
       "2016-03-28  45.36    36\n",
       "2016-03-29  45.63    35\n",
       "2016-03-30  42.64    43\n",
       "2016-03-31  50.38    57\n",
       "2016-04-01  50.06    44\n",
       "2016-04-02  61.66    81\n",
       "2016-04-03  61.88    67\n",
       "2016-04-04  48.37    56\n",
       "2016-04-05  42.68    50\n",
       "2016-04-06  44.11    43\n",
       "2016-04-07  45.67    42\n",
       "2016-04-08  58.37    59\n",
       "2016-04-09  65.02    64\n",
       "2016-04-10  61.37    79\n",
       "2016-04-11  46.04    55\n",
       "2016-04-12  44.61    35\n",
       "2016-04-13  41.24    35\n",
       "2016-04-14  47.99    36\n",
       "2016-04-15  57.30    60\n",
       "2016-04-16  67.03    68\n",
       "2016-04-17  64.04    69\n",
       "2016-04-18  45.01    48\n",
       "2016-04-19  42.69    34\n",
       "2016-04-20  41.65    49\n",
       "2016-04-21  48.28    39\n",
       "2016-04-22  59.68    59\n",
       "2016-04-23  65.39    45\n",
       "2016-04-24  62.80    58"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 144.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  25%|██▌       | 1/4 [03:34<10:42, 214.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  50%|█████     | 2/4 [07:15<07:16, 218.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  75%|███████▌  | 3/4 [11:31<03:55, 235.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid: 100%|██████████| 4/4 [17:49<00:00, 267.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30] \n",
      "  Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "  Backtesting metric: 194.87859200694615\n",
      "\n",
      "Mejores parámetros:                                                   lags  \\\n",
      "114  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "117  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "113  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "110  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "116  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "..                                                 ...   \n",
      "7                                [1, 2, 3, 4, 5, 6, 7]   \n",
      "10                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "36     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "9                                [1, 2, 3, 4, 5, 6, 7]   \n",
      "6                                [1, 2, 3, 4, 5, 6, 7]   \n",
      "\n",
      "                                            lags_label  \\\n",
      "114  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "117  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "113  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "110  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "116  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "..                                                 ...   \n",
      "7                                [1, 2, 3, 4, 5, 6, 7]   \n",
      "10                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "36     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "9                                [1, 2, 3, 4, 5, 6, 7]   \n",
      "6                                [1, 2, 3, 4, 5, 6, 7]   \n",
      "\n",
      "                                                params  mean_squared_error  \\\n",
      "114  {'max_depth': None, 'min_samples_leaf': 2, 'mi...          194.878592   \n",
      "117  {'max_depth': None, 'min_samples_leaf': 2, 'mi...          201.800730   \n",
      "113  {'max_depth': None, 'min_samples_leaf': 1, 'mi...          206.084998   \n",
      "110  {'max_depth': None, 'min_samples_leaf': 1, 'mi...          208.072492   \n",
      "116  {'max_depth': None, 'min_samples_leaf': 2, 'mi...          208.529533   \n",
      "..                                                 ...                 ...   \n",
      "7    {'max_depth': None, 'min_samples_leaf': 2, 'mi...          280.685986   \n",
      "10   {'max_depth': None, 'min_samples_leaf': 2, 'mi...          282.095654   \n",
      "36   {'max_depth': None, 'min_samples_leaf': 1, 'mi...          286.458040   \n",
      "9    {'max_depth': None, 'min_samples_leaf': 2, 'mi...          288.776079   \n",
      "6    {'max_depth': None, 'min_samples_leaf': 2, 'mi...          318.370338   \n",
      "\n",
      "     max_depth  min_samples_leaf  min_samples_split  n_estimators  \n",
      "114        NaN               2.0                2.0          50.0  \n",
      "117        NaN               2.0                5.0          50.0  \n",
      "113        NaN               1.0                5.0         200.0  \n",
      "110        NaN               1.0                2.0         200.0  \n",
      "116        NaN               2.0                2.0         200.0  \n",
      "..         ...               ...                ...           ...  \n",
      "7          NaN               2.0                2.0         100.0  \n",
      "10         NaN               2.0                5.0         100.0  \n",
      "36         NaN               1.0                2.0          50.0  \n",
      "9          NaN               2.0                5.0          50.0  \n",
      "6          NaN               2.0                2.0          50.0  \n",
      "\n",
      "[144 rows x 8 columns]\n",
      "Mejor RMSE: 194.87859200694615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo con un regressor base\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=RandomForestRegressor(random_state=42),\n",
    "    lags=14  # Esta es solo una configuración inicial, la ajustaremos con GridSearch\n",
    ")\n",
    "\n",
    "# Parámetros del RandomForest y los lags a buscar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Número de árboles en el bosque\n",
    "    'max_depth': [None, 5, 10],  # Profundidad máxima de los árboles\n",
    "    'min_samples_split': [2, 5],  # Muestras mínimas para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2],  # Muestras mínimas en una hoja\n",
    "}\n",
    "\n",
    "lags_grid = [7, 14, 21, 30]\n",
    "\n",
    "# Realizar el GridSearch\n",
    "results_grid = grid_search_forecaster(\n",
    "    forecaster=forecaster,\n",
    "    y=y_train,  # Serie temporal de entrenamiento\n",
    "    exog=exog_train,  # Variables exógenas si tienes alguna\n",
    "    param_grid=param_grid,  # La cuadrícula de parámetros\n",
    "    lags_grid=lags_grid,\n",
    "    steps=7,  # Cuántos pasos (días) predecir hacia adelante\n",
    "    metric='mean_squared_error',  # Métrica de evaluación (también puede ser MAE, etc.)\n",
    "    initial_train_size=len(y_train) - 30,  # Tamaño inicial de la ventana de entrenamiento\n",
    "    refit=True,  # Reentrenar el modelo en cada combinación de hiperparámetros\n",
    "    return_best=True,  # Devolver el mejor modelo\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Mostrar los mejores parámetros y el error\n",
    "print(f\"Mejores parámetros: {results_grid}\")\n",
    "print(f\"Mejor RMSE: {results_grid['mean_squared_error'].min()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 136.87741387849584\n",
      "El error RMSPE es: 19.73%\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=101,\n",
    "                                        max_depth=None,\n",
    "                                        min_samples_leaf=2, \n",
    "                                        min_samples_split=2,\n",
    "                                        n_estimators=50),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train, exog=exog_train)\n",
    "\n",
    "predicciones = forecaster.predict(steps=30,exog=exog_test)\n",
    "\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100\n",
    "\n",
    "print(f'El error RMSPE es: {rmspe:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>114.655246</td>\n",
       "      <td>120.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>127.007007</td>\n",
       "      <td>203.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>81.125745</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>78.130009</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>87.466670</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>90.145590</td>\n",
       "      <td>102.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>105.468281</td>\n",
       "      <td>79.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>125.799662</td>\n",
       "      <td>145.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>123.130791</td>\n",
       "      <td>120.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>81.626242</td>\n",
       "      <td>100.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>80.155844</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>78.970003</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>83.781057</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>95.079768</td>\n",
       "      <td>106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>121.169729</td>\n",
       "      <td>115.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>120.085559</td>\n",
       "      <td>142.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>80.519901</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>77.178319</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>78.479768</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>79.727401</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>92.455732</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>120.036198</td>\n",
       "      <td>122.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>127.628153</td>\n",
       "      <td>124.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>79.742741</td>\n",
       "      <td>86.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>77.874151</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>77.947671</td>\n",
       "      <td>88.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>78.019166</td>\n",
       "      <td>70.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>92.783978</td>\n",
       "      <td>106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>119.116003</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>124.453891</td>\n",
       "      <td>104.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pred   test\n",
       "2016-03-26  114.655246  120.6\n",
       "2016-03-27  127.007007  203.4\n",
       "2016-03-28   81.125745   64.8\n",
       "2016-03-29   78.130009   63.0\n",
       "2016-03-30   87.466670   77.4\n",
       "2016-03-31   90.145590  102.6\n",
       "2016-04-01  105.468281   79.2\n",
       "2016-04-02  125.799662  145.8\n",
       "2016-04-03  123.130791  120.6\n",
       "2016-04-04   81.626242  100.8\n",
       "2016-04-05   80.155844   90.0\n",
       "2016-04-06   78.970003   77.4\n",
       "2016-04-07   83.781057   75.6\n",
       "2016-04-08   95.079768  106.2\n",
       "2016-04-09  121.169729  115.2\n",
       "2016-04-10  120.085559  142.2\n",
       "2016-04-11   80.519901   99.0\n",
       "2016-04-12   77.178319   63.0\n",
       "2016-04-13   78.479768   63.0\n",
       "2016-04-14   79.727401   64.8\n",
       "2016-04-15   92.455732  108.0\n",
       "2016-04-16  120.036198  122.4\n",
       "2016-04-17  127.628153  124.2\n",
       "2016-04-18   79.742741   86.4\n",
       "2016-04-19   77.874151   61.2\n",
       "2016-04-20   77.947671   88.2\n",
       "2016-04-21   78.019166   70.2\n",
       "2016-04-22   92.783978  106.2\n",
       "2016-04-23  119.116003   81.0\n",
       "2016-04-24  124.453891  104.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "y_train[-30:].plot(ax=ax, label='Train')\n",
    "y_test[-30:].plot(ax=ax, label='Test')\n",
    "predicciones.plot(ax=ax, label='Predictions')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>weekday_Friday</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1913 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            event  weekday_Friday  weekday_Monday  weekday_Saturday  \\\n",
       "date                                                                  \n",
       "2011-01-29    0.0               0               0                 1   \n",
       "2011-01-30    0.0               0               0                 0   \n",
       "2011-01-31    0.0               0               1                 0   \n",
       "2011-02-01    0.0               0               0                 0   \n",
       "2011-02-02    0.0               0               0                 0   \n",
       "...           ...             ...             ...               ...   \n",
       "2016-04-20    0.0               0               0                 0   \n",
       "2016-04-21    0.0               0               0                 0   \n",
       "2016-04-22    0.0               1               0                 0   \n",
       "2016-04-23    0.0               0               0                 1   \n",
       "2016-04-24    0.0               0               0                 0   \n",
       "\n",
       "            weekday_Sunday  weekday_Thursday  weekday_Tuesday  \\\n",
       "date                                                            \n",
       "2011-01-29               0                 0                0   \n",
       "2011-01-30               1                 0                0   \n",
       "2011-01-31               0                 0                0   \n",
       "2011-02-01               0                 0                1   \n",
       "2011-02-02               0                 0                0   \n",
       "...                    ...               ...              ...   \n",
       "2016-04-20               0                 0                0   \n",
       "2016-04-21               0                 1                0   \n",
       "2016-04-22               0                 0                0   \n",
       "2016-04-23               0                 0                0   \n",
       "2016-04-24               1                 0                0   \n",
       "\n",
       "            weekday_Wednesday  \n",
       "date                           \n",
       "2011-01-29                  0  \n",
       "2011-01-30                  0  \n",
       "2011-01-31                  0  \n",
       "2011-02-01                  0  \n",
       "2011-02-02                  1  \n",
       "...                       ...  \n",
       "2016-04-20                  1  \n",
       "2016-04-21                  0  \n",
       "2016-04-22                  0  \n",
       "2016-04-23                  0  \n",
       "2016-04-24                  0  \n",
       "\n",
       "[1913 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>weekday</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1737770</th>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>45</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738770</th>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>58</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  sales   weekday  event\n",
       "1737770  2016-04-23     45  Saturday    0.0\n",
       "1738770  2016-04-24     58    Sunday    0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_predict = df_filtrado[['date', 'sales', 'weekday', 'event']]\n",
    "ts_predict.tail(2)\n",
    "# ts_predict = pd.get_dummies(data=ts_predict, columns=['weekday'], dtype=int)\n",
    "# ts_predict['date'] = pd.to_datetime(ts_predict['date'])\n",
    "# ts_predict.sort_values('date', ascending=True, inplace=True)\n",
    "# ts_predict.set_index('date', inplace=True)\n",
    "# ts_predict = ts_predict.asfreq('D')\n",
    "# y, exog = ts_predict['sales'], ts_predict.drop(columns=['sales'])\n",
    "\n",
    "# y_train, y_test = y[:-30], y[-30:]\n",
    "# exog_train, exog_test = exog[:-30], exog[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>weekday_Friday</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2016-05-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  event  weekday_Friday  weekday_Monday  weekday_Saturday  \\\n",
       "34 2016-05-29      0               0               0                 0   \n",
       "35 2016-05-30      0               0               1                 0   \n",
       "\n",
       "    weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \n",
       "34               1                 0                0                  0  \n",
       "35               0                 0                0                  0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '2016-04-25' \n",
    "end_date ='2016-05-30'\n",
    "# Crear un rango de fechas\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "# Crear el dataframe\n",
    "df1 = pd.DataFrame(date_range, columns=['date'])\n",
    "df1['weekday'] = df1['date'].dt.day_name()\n",
    "df1['event'] = 0\n",
    "df1 = pd.get_dummies(data=df1, columns=['weekday'], dtype=int)\n",
    "df1.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sort_values('date', inplace=True, ascending=True)\n",
    "df1.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>weekday_Friday</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-04-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            event  weekday_Friday  weekday_Monday  weekday_Saturday  \\\n",
       "date                                                                  \n",
       "2016-04-25      0               0               1                 0   \n",
       "\n",
       "            weekday_Sunday  weekday_Thursday  weekday_Tuesday  \\\n",
       "date                                                            \n",
       "2016-04-25               0                 0                0   \n",
       "\n",
       "            weekday_Wednesday  \n",
       "date                           \n",
       "2016-04-25                  0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>weekday_Friday</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            event  weekday_Friday  weekday_Monday  weekday_Saturday  \\\n",
       "date                                                                  \n",
       "2016-03-26    0.0               0               0                 1   \n",
       "\n",
       "            weekday_Sunday  weekday_Thursday  weekday_Tuesday  \\\n",
       "date                                                            \n",
       "2016-03-26               0                 0                0   \n",
       "\n",
       "            weekday_Wednesday  \n",
       "date                           \n",
       "2016-03-26                  0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_test = pd.concat([exog_test, df1], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>weekday_Friday</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            event  weekday_Friday  weekday_Monday  weekday_Saturday  \\\n",
       "date                                                                  \n",
       "2016-05-30    0.0               0               1                 0   \n",
       "\n",
       "            weekday_Sunday  weekday_Thursday  weekday_Tuesday  \\\n",
       "date                                                            \n",
       "2016-05-30               0                 0                0   \n",
       "\n",
       "            weekday_Wednesday  \n",
       "date                           \n",
       "2016-05-30                  0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog_test.tail(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
