{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harol\\Nuclio\\DS-MARKET-TFM\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import skforecast\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.utils import save_forecaster\n",
    "from skforecast.utils import load_forecaster\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo Dataset principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_csv('../../data/ts_top100_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>income</th>\n",
       "      <th>event</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>ACCESORIES_1_108_NYC_1</td>\n",
       "      <td>ACCESORIES_1_108</td>\n",
       "      <td>4</td>\n",
       "      <td>64.4784</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_027_NYC_1</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_027</td>\n",
       "      <td>4</td>\n",
       "      <td>26.2000</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_053_NYC_1</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_140_NYC_1</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_140</td>\n",
       "      <td>4</td>\n",
       "      <td>75.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_177_NYC_1</td>\n",
       "      <td>HOME_&amp;_GARDEN_1_177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                         id                 item  sales   income  \\\n",
       "0 2011-01-29     ACCESORIES_1_108_NYC_1     ACCESORIES_1_108      4  64.4784   \n",
       "1 2011-01-29  HOME_&_GARDEN_1_027_NYC_1  HOME_&_GARDEN_1_027      4  26.2000   \n",
       "2 2011-01-29  HOME_&_GARDEN_1_053_NYC_1  HOME_&_GARDEN_1_053      0   0.0000   \n",
       "3 2011-01-29  HOME_&_GARDEN_1_140_NYC_1  HOME_&_GARDEN_1_140      4  75.0000   \n",
       "4 2011-01-29  HOME_&_GARDEN_1_177_NYC_1  HOME_&_GARDEN_1_177      0   0.0000   \n",
       "\n",
       "   event   weekday  \n",
       "0      0  Saturday  \n",
       "1      0  Saturday  \n",
       "2      0  Saturday  \n",
       "3      0  Saturday  \n",
       "4      0  Saturday  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['date']= pd.to_datetime(ts['date'], format='%Y-%m-%d')\n",
    "ts['weekday'] = ts['date'].dt.day_name()\n",
    "ts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = ts.copy()\n",
    "df_filtrado = df_original[(df_original['id'] == 'SUPERMARKET_3_586_BOS_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_predict = df_filtrado[['date', 'sales', 'weekday', 'event']]\n",
    "ts_predict = pd.get_dummies(data=ts_predict, columns=['weekday'], dtype=int)\n",
    "ts_predict['date'] = pd.to_datetime(ts_predict['date'])\n",
    "ts_predict.sort_values('date', ascending=True, inplace=True)\n",
    "ts_predict.set_index('date', inplace=True)\n",
    "ts_predict = ts_predict.asfreq('D')\n",
    "y, exog = ts_predict['sales'], ts_predict.drop(columns=['sales'])\n",
    "\n",
    "y_train, y_test = y[:-30], y[-30:]\n",
    "exog_train, exog_test = exog[:-30], exog[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error(MSE): 282.0832566666667\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train)\n",
    "predicciones = forecaster.predict(steps=30)\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f'The error(MSE): {error_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>54.65</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>49.92</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>47.69</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>54.94</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>48.55</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>54.20</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>53.42</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>47.05</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>45.38</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>42.86</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>44.30</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>51.73</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>49.06</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>53.69</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>47.39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>45.47</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>46.13</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>46.91</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>52.14</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>53.94</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>50.41</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>43.54</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>42.89</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>44.03</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>46.53</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>52.60</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>53.18</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>48.27</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>44.44</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>43.55</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pred  test\n",
       "2016-03-26  54.65    75\n",
       "2016-03-27  49.92    68\n",
       "2016-03-28  47.69    54\n",
       "2016-03-29  54.94    22\n",
       "2016-03-30  48.55    38\n",
       "2016-03-31  54.20    44\n",
       "2016-04-01  53.42    40\n",
       "2016-04-02  47.05    55\n",
       "2016-04-03  45.38    74\n",
       "2016-04-04  42.86    61\n",
       "2016-04-05  44.30    65\n",
       "2016-04-06  51.73    44\n",
       "2016-04-07  49.06    74\n",
       "2016-04-08  53.69    54\n",
       "2016-04-09  47.39    52\n",
       "2016-04-10  45.47    75\n",
       "2016-04-11  46.13    38\n",
       "2016-04-12  46.91    39\n",
       "2016-04-13  52.14    47\n",
       "2016-04-14  53.94    42\n",
       "2016-04-15  50.41    53\n",
       "2016-04-16  43.54    50\n",
       "2016-04-17  42.89    68\n",
       "2016-04-18  44.03    72\n",
       "2016-04-19  46.53    81\n",
       "2016-04-20  52.60    45\n",
       "2016-04-21  53.18    59\n",
       "2016-04-22  48.27    50\n",
       "2016-04-23  44.44    56\n",
       "2016-04-24  43.55    58"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CON HIPERPARAMETROS SIN EXOGENAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid: 100%|██████████| 7/7 [11:31<00:00, 98.73s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
      "  Parameters: {'max_depth': 3, 'n_estimators': 100}\n",
      "  Backtesting metric: 1148.6678367369022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroldavis/Projects/DS-MARKET-TFM/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:307: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters: grid search\n",
    "# ==============================================================================\n",
    "steps = 7\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 7 # This value will be replaced in the grid search\n",
    "             )\n",
    "\n",
    "# Candidate values for lags\n",
    "lags_grid = [3,4,5,7,8,10,14]\n",
    "\n",
    "# Candidate values for regressor's hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 250],\n",
    "    'max_depth': [3, 8]\n",
    "}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                   forecaster         = forecaster,\n",
    "                   y                  = y_train,\n",
    "                   param_grid         = param_grid,\n",
    "                   lags_grid          = lags_grid,\n",
    "                   steps              = steps,\n",
    "                   metric             = 'mean_squared_error',\n",
    "                   initial_train_size = int(len(y_train)*0.5),\n",
    "                   fixed_train_size   = False,\n",
    "                   refit              = False,\n",
    "                   skip_folds         = None,\n",
    "                   return_best        = True,\n",
    "                   n_jobs             = 'auto',\n",
    "                   verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 207.0800577038751\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=10,\n",
    "                                        max_depth=3,\n",
    "                                        #min_samples_leaf=2, \n",
    "                                        #min_samples_split=5,\n",
    "                                        n_estimators=100),\n",
    "        lags=14\n",
    "    )\n",
    "forecaster.fit(y=y_train)\n",
    "predicciones = forecaster.predict(steps=30)\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>60.671804</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>59.011846</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>56.072191</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>56.339372</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>53.200320</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>53.398840</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>53.031724</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>52.666401</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>51.336534</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>50.298094</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>50.427949</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>51.960192</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>50.822692</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>51.853856</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>52.454252</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>51.733122</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>51.359275</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>50.960954</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>50.985351</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>50.864598</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>50.985351</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>50.985351</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>50.882377</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>50.761624</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>50.761624</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>50.761624</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>50.761624</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>50.761624</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>50.761624</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>50.761624</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred  test\n",
       "2016-03-26  60.671804    75\n",
       "2016-03-27  59.011846    68\n",
       "2016-03-28  56.072191    54\n",
       "2016-03-29  56.339372    22\n",
       "2016-03-30  53.200320    38\n",
       "2016-03-31  53.398840    44\n",
       "2016-04-01  53.031724    40\n",
       "2016-04-02  52.666401    55\n",
       "2016-04-03  51.336534    74\n",
       "2016-04-04  50.298094    61\n",
       "2016-04-05  50.427949    65\n",
       "2016-04-06  51.960192    44\n",
       "2016-04-07  50.822692    74\n",
       "2016-04-08  51.853856    54\n",
       "2016-04-09  52.454252    52\n",
       "2016-04-10  51.733122    75\n",
       "2016-04-11  51.359275    38\n",
       "2016-04-12  50.960954    39\n",
       "2016-04-13  50.985351    47\n",
       "2016-04-14  50.864598    42\n",
       "2016-04-15  50.985351    53\n",
       "2016-04-16  50.985351    50\n",
       "2016-04-17  50.882377    68\n",
       "2016-04-18  50.761624    72\n",
       "2016-04-19  50.761624    81\n",
       "2016-04-20  50.761624    45\n",
       "2016-04-21  50.761624    59\n",
       "2016-04-22  50.761624    50\n",
       "2016-04-23  50.761624    56\n",
       "2016-04-24  50.761624    58"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con exógenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 209.15058666666667\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=11),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train, exog=exog_train)\n",
    "\n",
    "predicciones = forecaster.predict(steps=30, exog=exog_test)\n",
    "\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>63.87</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>70.68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>52.42</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>55.95</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>51.15</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>53.73</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>51.40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>49.56</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>53.88</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>46.93</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>46.18</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>49.43</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>48.50</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>52.33</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>58.50</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>60.31</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>46.94</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>44.52</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>46.84</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>49.63</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>51.29</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>54.65</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>57.22</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>44.92</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>42.94</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>42.64</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>46.31</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>51.42</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>56.04</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>59.94</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pred  test\n",
       "2016-03-26  63.87    75\n",
       "2016-03-27  70.68    68\n",
       "2016-03-28  52.42    54\n",
       "2016-03-29  55.95    22\n",
       "2016-03-30  51.15    38\n",
       "2016-03-31  53.73    44\n",
       "2016-04-01  51.40    40\n",
       "2016-04-02  49.56    55\n",
       "2016-04-03  53.88    74\n",
       "2016-04-04  46.93    61\n",
       "2016-04-05  46.18    65\n",
       "2016-04-06  49.43    44\n",
       "2016-04-07  48.50    74\n",
       "2016-04-08  52.33    54\n",
       "2016-04-09  58.50    52\n",
       "2016-04-10  60.31    75\n",
       "2016-04-11  46.94    38\n",
       "2016-04-12  44.52    39\n",
       "2016-04-13  46.84    47\n",
       "2016-04-14  49.63    42\n",
       "2016-04-15  51.29    53\n",
       "2016-04-16  54.65    50\n",
       "2016-04-17  57.22    68\n",
       "2016-04-18  44.92    72\n",
       "2016-04-19  42.94    81\n",
       "2016-04-20  42.64    45\n",
       "2016-04-21  46.31    59\n",
       "2016-04-22  51.42    50\n",
       "2016-04-23  56.04    56\n",
       "2016-04-24  59.94    58"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 144.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  25%|██▌       | 1/4 [01:25<04:15, 85.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  50%|█████     | 2/4 [03:25<03:31, 105.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:  75%|███████▌  | 3/4 [06:28<02:20, 140.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 1853\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 5\n",
      "    Number skipped folds: 0 \n",
      "    Number of steps per fold: 7\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2011-01-29 00:00:00 -- 2016-02-24 00:00:00  (n=1853)\n",
      "    Validation: 2016-02-25 00:00:00 -- 2016-03-02 00:00:00  (n=7)\n",
      "Fold: 1\n",
      "    Training:   2011-02-05 00:00:00 -- 2016-03-02 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-03 00:00:00 -- 2016-03-09 00:00:00  (n=7)\n",
      "Fold: 2\n",
      "    Training:   2011-02-12 00:00:00 -- 2016-03-09 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-10 00:00:00 -- 2016-03-16 00:00:00  (n=7)\n",
      "Fold: 3\n",
      "    Training:   2011-02-19 00:00:00 -- 2016-03-16 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-17 00:00:00 -- 2016-03-23 00:00:00  (n=7)\n",
      "Fold: 4\n",
      "    Training:   2011-02-26 00:00:00 -- 2016-03-23 00:00:00  (n=1853)\n",
      "    Validation: 2016-03-24 00:00:00 -- 2016-03-25 00:00:00  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid: 100%|██████████| 4/4 [11:03<00:00, 166.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30] \n",
      "  Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "  Backtesting metric: 75.71402666666667\n",
      "\n",
      "Mejores parámetros:                                                   lags  \\\n",
      "108  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "21                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "18                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "19                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "22                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "..                                                 ...   \n",
      "37     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "36     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "39     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "42     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "45     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "\n",
      "                                            lags_label  \\\n",
      "108  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "21                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "18                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "19                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "22                               [1, 2, 3, 4, 5, 6, 7]   \n",
      "..                                                 ...   \n",
      "37     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "36     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "39     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "42     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "45     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
      "\n",
      "                                                params  mean_squared_error  \\\n",
      "108  {'max_depth': None, 'min_samples_leaf': 1, 'mi...           75.714027   \n",
      "21   {'max_depth': 5, 'min_samples_leaf': 2, 'min_s...           77.943528   \n",
      "18   {'max_depth': 5, 'min_samples_leaf': 2, 'min_s...           77.943528   \n",
      "19   {'max_depth': 5, 'min_samples_leaf': 2, 'min_s...           78.231801   \n",
      "22   {'max_depth': 5, 'min_samples_leaf': 2, 'min_s...           78.231801   \n",
      "..                                                 ...                 ...   \n",
      "37   {'max_depth': None, 'min_samples_leaf': 1, 'mi...          104.029190   \n",
      "36   {'max_depth': None, 'min_samples_leaf': 1, 'mi...          108.757400   \n",
      "39   {'max_depth': None, 'min_samples_leaf': 1, 'mi...          110.536027   \n",
      "42   {'max_depth': None, 'min_samples_leaf': 2, 'mi...          111.353349   \n",
      "45   {'max_depth': None, 'min_samples_leaf': 2, 'mi...          112.130541   \n",
      "\n",
      "     max_depth  min_samples_leaf  min_samples_split  n_estimators  \n",
      "108        NaN               1.0                2.0          50.0  \n",
      "21         5.0               2.0                5.0          50.0  \n",
      "18         5.0               2.0                2.0          50.0  \n",
      "19         5.0               2.0                2.0         100.0  \n",
      "22         5.0               2.0                5.0         100.0  \n",
      "..         ...               ...                ...           ...  \n",
      "37         NaN               1.0                2.0         100.0  \n",
      "36         NaN               1.0                2.0          50.0  \n",
      "39         NaN               1.0                5.0          50.0  \n",
      "42         NaN               2.0                2.0          50.0  \n",
      "45         NaN               2.0                5.0          50.0  \n",
      "\n",
      "[144 rows x 8 columns]\n",
      "Mejor RMSE: 75.71402666666667\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo con un regressor base\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=RandomForestRegressor(random_state=42),\n",
    "    lags=14  # Esta es solo una configuración inicial, la ajustaremos con GridSearch\n",
    ")\n",
    "\n",
    "# Parámetros del RandomForest y los lags a buscar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Número de árboles en el bosque\n",
    "    'max_depth': [None, 5, 10],  # Profundidad máxima de los árboles\n",
    "    'min_samples_split': [2, 5],  # Muestras mínimas para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2],  # Muestras mínimas en una hoja\n",
    "}\n",
    "\n",
    "lags_grid = [7, 14, 21, 30]\n",
    "\n",
    "# Realizar el GridSearch\n",
    "results_grid = grid_search_forecaster(\n",
    "    forecaster=forecaster,\n",
    "    y=y_train,  # Serie temporal de entrenamiento\n",
    "    exog=exog_train,  # Variables exógenas si tienes alguna\n",
    "    param_grid=param_grid,  # La cuadrícula de parámetros\n",
    "    lags_grid=lags_grid,\n",
    "    steps=7,  # Cuántos pasos (días) predecir hacia adelante\n",
    "    metric='mean_squared_error',  # Métrica de evaluación (también puede ser MAE, etc.)\n",
    "    initial_train_size=len(y_train) - 30,  # Tamaño inicial de la ventana de entrenamiento\n",
    "    refit=True,  # Reentrenar el modelo en cada combinación de hiperparámetros\n",
    "    return_best=True,  # Devolver el mejor modelo\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Mostrar los mejores parámetros y el error\n",
    "print(f\"Mejores parámetros: {results_grid}\")\n",
    "print(f\"Mejor RMSE: {results_grid['mean_squared_error'].min()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (MSE): 209.81191695449678\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "        regressor=RandomForestRegressor(random_state=101,\n",
    "                                        max_depth=None,\n",
    "                                        min_samples_leaf=2, \n",
    "                                        min_samples_split=2,\n",
    "                                        n_estimators=50),\n",
    "        lags=14\n",
    "    )\n",
    "\n",
    "forecaster.fit(y=y_train, exog=exog_train)\n",
    "\n",
    "predicciones = forecaster.predict(steps=30,exog=exog_test)\n",
    "\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = y_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Test error (MSE): {error_mse}\")\n",
    "rmspe = np.sqrt(np.mean(((y_test - predicciones) / y_test) ** 2)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>63.418286</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>67.630143</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>51.770611</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>56.415095</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>51.514159</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>53.222333</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>50.608984</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>49.755048</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>52.929778</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>47.314206</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>46.161643</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>49.044929</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>46.597183</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>48.672667</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>57.999310</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>60.701833</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>45.525778</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>46.878238</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>46.822667</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>48.348190</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>50.717286</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>54.785000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>55.523024</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>45.846976</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>43.952305</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>45.742048</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>48.577302</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>48.140190</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>56.229230</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>62.430952</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred  test\n",
       "2016-03-26  63.418286    75\n",
       "2016-03-27  67.630143    68\n",
       "2016-03-28  51.770611    54\n",
       "2016-03-29  56.415095    22\n",
       "2016-03-30  51.514159    38\n",
       "2016-03-31  53.222333    44\n",
       "2016-04-01  50.608984    40\n",
       "2016-04-02  49.755048    55\n",
       "2016-04-03  52.929778    74\n",
       "2016-04-04  47.314206    61\n",
       "2016-04-05  46.161643    65\n",
       "2016-04-06  49.044929    44\n",
       "2016-04-07  46.597183    74\n",
       "2016-04-08  48.672667    54\n",
       "2016-04-09  57.999310    52\n",
       "2016-04-10  60.701833    75\n",
       "2016-04-11  45.525778    38\n",
       "2016-04-12  46.878238    39\n",
       "2016-04-13  46.822667    47\n",
       "2016-04-14  48.348190    42\n",
       "2016-04-15  50.717286    53\n",
       "2016-04-16  54.785000    50\n",
       "2016-04-17  55.523024    68\n",
       "2016-04-18  45.846976    72\n",
       "2016-04-19  43.952305    81\n",
       "2016-04-20  45.742048    45\n",
       "2016-04-21  48.577302    59\n",
       "2016-04-22  48.140190    50\n",
       "2016-04-23  56.229230    56\n",
       "2016-04-24  62.430952    58"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(predicciones)\n",
    "result['test']= y_test\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "y_train[-30:].plot(ax=ax, label='Train')\n",
    "y_test[-30:].plot(ax=ax, label='Test')\n",
    "predicciones.plot(ax=ax, label='Predictions')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
