{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = pd.read_csv('./data/item_prices.csv')\n",
    "df_calendar = pd.read_csv('./data/daily_calendar_with_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_prices.shape)\n",
    "df_prices.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices[df_prices.duplicated(keep=False)]\n",
    "df_prices.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I filter with groupby, for _items_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_price = df_prices.groupby(['item']).agg(\n",
    "    price_min = ('sell_price', 'min'),\n",
    "    price_max = ('sell_price', 'max'),\n",
    "    price_mean = ('sell_price', 'mean')\n",
    ").reset_index()\n",
    "print(df_new_price.shape)\n",
    "df_new_price.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"df_price_cluster.csv\"\n",
    "# df_new_price .to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new list of date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df_calendar['date'].min()\n",
    "end_date = df_calendar['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yearweek_df(start_date_str, end_date_str, initial_week):\n",
    "    #Convertir las cadenas de fecha a objetos datetime\n",
    "    start_date = pd.to_datetime(start_date_str)\n",
    "    end_date = pd.to_datetime(end_date_str)\n",
    "\n",
    "    # Generar el rango de fechas\n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "    df = pd.DataFrame(date_range, columns=['date'])\n",
    "\n",
    "    # Calcular el número de días desde la fecha de inicio\n",
    "    df['dias_desde_inicio'] = (df['date'] - start_date).dt.days\n",
    "\n",
    "    # Calcular el número de la semana ajustado desde la fecha inicial\n",
    "    df['week_number'] = ((df['dias_desde_inicio'] // 7) + initial_week).astype(int)\n",
    "\n",
    "    # Crear una columna 'yearweek' que combine el año y la semana\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['yearweek'] = df['year'].astype(str) + df['week_number'].apply(lambda x: f\"{x:02d}\")\n",
    "\n",
    "    # Eliminar las columnas auxiliares\n",
    "    df.drop(['dias_desde_inicio', 'week_number', 'year'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "    # Crear DataFrames para cada año\n",
    "df_2011 = create_yearweek_df('2011-01-29', '2011-12-30', 5)\n",
    "df_2012_1 = create_yearweek_df('2011-12-31', '2012-01-01', 0)\n",
    "df_2012 = create_yearweek_df('2012-01-02', '2012-12-30', 1)\n",
    "df_2012_53 = pd.DataFrame([['2012-12-31','201253']],columns=['date','yearweek'])\n",
    "df_2013 = create_yearweek_df('2013-01-01', '2013-12-31', 0)\n",
    "df_2014 = create_yearweek_df('2014-01-01', '2014-12-31', 0)\n",
    "df_2015 = create_yearweek_df('2015-01-01', '2015-12-31', 0)\n",
    "df_2016_1 = create_yearweek_df('2016-01-01', '2016-01-02', 0)\n",
    "df_2016 = create_yearweek_df('2016-01-03', '2016-04-24', 1)\n",
    "\n",
    "df_2012_1.loc[0,'yearweek']='201152'\n",
    "\n",
    "all_years_df = pd.concat([df_2011, df_2012_1, df_2012, df_2012_53, df_2013, df_2014, df_2015,df_2016_1, df_2016]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years_df['date']= pd.to_datetime(all_years_df['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years_df['yearweek'] = all_years_df['yearweek'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices['yearweek'] = df_prices['yearweek'].astype(str).apply(lambda x: x[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_prices.merge(all_years_df, on=['yearweek'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
